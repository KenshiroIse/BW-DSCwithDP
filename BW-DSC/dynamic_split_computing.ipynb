{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     17\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/EdMIPS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from math import ceil\n",
    "from torchinfo import summary\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "os.chdir('/EdMIPS')\n",
    "# EdMIPS/models ディレクトリへのパスを追加\n",
    "sys.path.append('/EdMIPS/models')\n",
    "import models as mymodels\n",
    "from matplotlib.colors import ListedColormap\n",
    "from pprint import pprint\n",
    "import matplotlib.ticker as ticker\n",
    "from models.quant_efficientnet import BasicCNNBlock\n",
    "\n",
    "VERSION = 0\n",
    "SELECTED_GPUS = [0, 1]\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(gpu_number) for gpu_number in SELECTED_GPUS])\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# GPUの存在を確認\n",
    "if torch.cuda.device_count() < 2:\n",
    "    raise RuntimeError(\"このコードは少なくとも2つのGPUが必要です。\")\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "print('Number of devices: {}'.format(device_count))\n",
    "\n",
    "for gpu in range(device_count):\n",
    "    print(f\"Device {gpu}: {torch.cuda.get_device_name(gpu)}\")\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "# カレントディレクトリを 'EdMIPS' に変更\n",
    "os.chdir('/EdMIPS')\n",
    "\n",
    "\n",
    "BATCH_TABLE_DIR = 'batch_table'\n",
    "if not os.path.exists(BATCH_TABLE_DIR):\n",
    "    os.makedirs(BATCH_TABLE_DIR)\n",
    "\n",
    "PLOT_LINESTYLES = ['-', '--', '-.', ':']\n",
    "PLOT_MARKERS = ['o', 'v', 'P', 'X', 'D', '^', 's']\n",
    "FIGURE_SIZE = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_arch(arch_path, names_nbits):\n",
    "    checkpoint = torch.load(arch_path)\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    best_arch, worst_arch = {}, {}\n",
    "    for name in names_nbits.keys():\n",
    "        best_arch[name], worst_arch[name] = [], []\n",
    "    for name, params in state_dict.items():\n",
    "        name = name.split('.')[-1]\n",
    "        if name in names_nbits.keys():\n",
    "            alpha = params.cpu().numpy()\n",
    "            assert names_nbits[name] == alpha.shape[0]\n",
    "            best_arch[name].append(alpha.argmax())\n",
    "            worst_arch[name].append(alpha.argmin())\n",
    "\n",
    "    return best_arch, worst_arch\n",
    "\n",
    "def get_model(config):\n",
    "    if config[\"model_name\"] == 'vgg-16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        # model.classifier[6] = nn.Linear(4096, config[\"num_classes\"])\n",
    "    elif config[\"model_name\"] == 'vgg-19':\n",
    "        model = models.vgg19(pretrained=True)\n",
    "        # model.classifier[6] = nn.Linear(4096, config[\"num_classes\"])\n",
    "    elif config[\"model_name\"] == 'resnet-18':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        # model.fc = nn.Linear(512, config[\"num_classes\"])\n",
    "    elif config[\"model_name\"] == 'resnet-34':\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        # model.fc = nn.Linear(512, config[\"num_classes\"])\n",
    "    elif config[\"model_name\"] == 'resnet-50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        # model.fc = nn.Linear(2048, config[\"num_classes\"])\n",
    "    elif config[\"model_name\"] == 'resnet-101':\n",
    "        model = models.resnet101(pretrained=True)\n",
    "        # model.fc = nn.Linear(2048, config[\"num_classes\"])\n",
    "    \n",
    "    elif config[\"model_name\"] == 'quanteffnet_w8a8':\n",
    "        archas = [8] *80\n",
    "        model = mymodels.__dict__[config[\"model_name\"]](\"path\")\n",
    "        \n",
    "    elif config[\"model_name\"] == 'quanteffnet_cfg_2468':\n",
    "        wbits, abits = [2, 4, 6, 8],  [2, 4, 6, 8]\n",
    "        name_nbits = {'alpha_activ': len(abits), 'alpha_weight': len(wbits)}\n",
    "        best_arch, worst_arch = _load_arch(config[\"arch_path\"], name_nbits)\n",
    "        archas = [abits[a] for a in best_arch['alpha_activ']]\n",
    "        model =  mymodels.__dict__[config[\"model_name\"]](config[\"arch_path\"])\n",
    "        \n",
    "    elif config[\"model_name\"] == 'quanteffnet_w8a8_b3':\n",
    "        archas = [8] *129\n",
    "        model = model = mymodels.__dict__[config[\"model_name\"]](\"path\")\n",
    "        \n",
    "    elif config[\"model_name\"] == 'quanteffnet_cfg_2468_b3':\n",
    "        wbits, abits = [2, 4, 6, 8],  [2, 4, 6, 8]\n",
    "        name_nbits = {'alpha_activ': len(abits), 'alpha_weight': len(wbits)}\n",
    "        best_arch, worst_arch = _load_arch(config[\"arch_path\"], name_nbits)\n",
    "        archas = [abits[a] for a in best_arch['alpha_activ']]\n",
    "        model = mymodels.__dict__[config[\"model_name\"]](config[\"arch_path\"])\n",
    "        \n",
    "    elif config[\"model_name\"] == 'efficient_baseline':\n",
    "        archas = [2] *80     # 全ての層の分割点を計測したいため、分割点が選ばれるように2bitで計測\n",
    "        model = mymodels.__dict__[\"quanteffnet_w8a8\"](\"path\")\n",
    "        \n",
    "    elif config[\"model_name\"] == 'efficientb3_baseline':\n",
    "        archas = [2] *129     # 全ての層の分割点を計測したいため、分割点が選ばれるように2bitで計測\n",
    "        model = mymodels.__dict__[\"quanteffnet_w8a8_b3\"](\"path\")\n",
    "    # 変更箇所\n",
    "    elif config[\"model_name\"] == 'quanteffnet_cfg':\n",
    "        wbits, abits = [2, 4, 6, 8],  [2, 3, 4]\n",
    "        name_nbits = {'alpha_activ': len(abits), 'alpha_weight': len(wbits)}\n",
    "        best_arch, worst_arch = _load_arch(config[\"arch_path\"], name_nbits)\n",
    "        archas = [abits[a] for a in best_arch['alpha_activ']]\n",
    "        model = mymodels.__dict__[config[\"model_name\"]](config[\"arch_path\"])\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_name: {config['model_name']}\")\n",
    "    return model, archas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_natural_bottlenecks(model, input_size, act_bits, compressive_only=True):\n",
    "    # 各層のinputサイズを計算して、圧縮率が最も高い層を探す\n",
    "    natural_bottlenecks = []\n",
    "    best_compression = 1.0\n",
    "    cnn_count = 0  # CNNレイヤーのカウント\n",
    "    input_bit = 8 # 入力のbit数\n",
    "    min_bit = 8  # 探索する最小のbit数←使って無くない？\n",
    "    bit_compression = [act_bit / input_bit for act_bit in act_bits]\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    mock_input = torch.randn(1, 3, input_size, input_size).to(device)\n",
    "    previous_size = torch.prod(torch.tensor(mock_input.shape[1:])).item()\n",
    "\n",
    "    for i, module in enumerate(model.features):\n",
    "        # print(i, module)\n",
    "        block_number = i-1 \n",
    "        # 0はfeaturesの最初のBasicCNNBlockなので、1から始める\n",
    "        if isinstance(module, BasicCNNBlock):\n",
    "            print(f\"Encountered BasicBlock at features.{i}\")\n",
    "            output = module(mock_input)\n",
    "            mock_input = output.detach()\n",
    "            continue\n",
    "        \n",
    "        input_size_layer = torch.prod(torch.tensor(mock_input.shape[1:])).item()\n",
    "        if input_size_layer * act_bits[cnn_count] < input_size * input_size * 3 * input_bit:\n",
    "            compression = float(input_size_layer) / (input_size * input_size * 3)\n",
    "            compression *= bit_compression[cnn_count]\n",
    "            print(i,block_number)\n",
    "            if not compressive_only or compression < best_compression:\n",
    "                natural_bottlenecks.append({\n",
    "                    'layer_name': \"blocks_{}\".format(block_number),\n",
    "                    'compression': compression,\n",
    "                    'cnn_layer_number': cnn_count,  # ここでCNNレイヤーの番号を記録\n",
    "                    'block_number': block_number,  \n",
    "                })\n",
    "                best_compression = compression\n",
    "        output = module(mock_input)\n",
    "        mock_input = output.detach()\n",
    "        \n",
    "        cnn_count += count_conv2d_layers(module)\n",
    "    return natural_bottlenecks\n",
    "\n",
    "def count_conv2d_layers(model):\n",
    "    count = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            count += 1\n",
    "        elif isinstance(module, nn.Sequential):\n",
    "            # Sequentialブロック内でさらにConv2dを探す\n",
    "            for sub_module in module:\n",
    "                if isinstance(sub_module, nn.Conv2d):\n",
    "                    count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_time(model, batch_size, device, repetitions=300, input_shape=None, intermediate=None,):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the inference time of a model for a given input shape and batch size.\n",
    "    \"\"\"\n",
    "    # モデルを評価モードに設定し、適切なデバイスに移動\n",
    "    model = model.eval().to(device)\n",
    "\n",
    "    if input_shape is None:\n",
    "        input_shape = (batch_size, 3, config['image_size'], config['image_size'])\n",
    "    else:\n",
    "        input_shape = (batch_size,) + input_shape[1:]\n",
    "    \n",
    "    if intermediate is None:\n",
    "        input_data = torch.ones(input_shape, device=device)  # the original code uses dtype=torch.float16, which would be 2 bytes\n",
    "    else:\n",
    "        # input_data = intermediate.to(device)\n",
    "        input_data = intermediate\n",
    "\n",
    "    # ウォームアップフェーズ\n",
    "    with torch.no_grad():\n",
    "        # for _ in range(repetitions):   #10回程度で十分\n",
    "        for _ in range(10): \n",
    "            model(input_data)\n",
    "            \n",
    "    # CUDAカーネルの同期化        \n",
    "    torch.cuda.synchronize(device)  # Make sure all CUDA operations have finished\n",
    "\n",
    "    # 推論時間の計測開始\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(repetitions):\n",
    "            model(input_data)\n",
    "            \n",
    "    # 再度、CUDAカーネルの同期化\n",
    "    torch.cuda.synchronize(device)\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    # 平均推論時間をミリ秒単位で計算\n",
    "    inference_time = (end - start) / repetitions * 1000  # ミリ秒単位\n",
    "    return inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数はなんのためにある？\n",
    "def get_batch_table_path(config):\n",
    "    if 'CPU' in config['processors']['weak']:\n",
    "        return os.path.join(BATCH_TABLE_DIR, '%s_%s_v%d.json' % (\n",
    "            config['model_name'],\n",
    "            config['processors']['weak'].replace('/', ''),\n",
    "            VERSION\n",
    "        ))\n",
    "    else:  # legacy name\n",
    "       return os.path.join(BATCH_TABLE_DIR, '%s_v%d.json' % (\n",
    "           config['model_name'],\n",
    "           VERSION\n",
    "       ))\n",
    "\n",
    "def save_batch_table(batch_table, config):\n",
    "    batch_table_path = get_batch_table_path(config)\n",
    "    with open(batch_table_path, 'w') as batch_table_file:\n",
    "        json.dump(batch_table, batch_table_file)\n",
    "\n",
    "def load_batch_table(config):\n",
    "    batch_table_path = get_batch_table_path(config)\n",
    "    with open(batch_table_path, 'r') as batch_table_file:\n",
    "        return json.load(batch_table_file)\n",
    "    \n",
    "    \n",
    "def create_batch_table(config):\n",
    "    # 一回で計測できるコードにできるはず\n",
    "    model, act_bits = get_model(config)\n",
    "\n",
    "    natural_bottlenecks = get_natural_bottlenecks(model, config[\"image_size\"], act_bits)\n",
    "    cnn_layer_numbers = [bottleneck['cnn_layer_number'] for bottleneck in natural_bottlenecks]\n",
    "    block_numbers = [bottleneck['block_number'] for bottleneck in natural_bottlenecks]\n",
    "    \n",
    "    batch_table = {}\n",
    "\n",
    "    for batch_size in config['batch_sizes']:\n",
    "        print('Batch Size:', batch_size)\n",
    "        batch_table[batch_size] = {}\n",
    "\n",
    "        sys.stdout.write('\\r%d/%d' % (1, len(natural_bottlenecks) + 2))\n",
    "        sys.stdout.flush()\n",
    "        batch_table[batch_size]['whole_device'] = get_inference_time(model, batch_size, device=config['processors']['weak']) \n",
    "    \n",
    "        sys.stdout.write('\\r%d/%d' % (2, len(natural_bottlenecks) + 2))\n",
    "        sys.stdout.flush()\n",
    "        batch_table[batch_size]['whole_edge'] = get_inference_time(model, batch_size, device=config['processors']['strong']) #full offloading\n",
    "\n",
    "        for i, bottleneck in enumerate(natural_bottlenecks):\n",
    "            sys.stdout.write('\\r%d/%d' % (i + 3, len(natural_bottlenecks) + 2))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if config['model_name'].startswith('efficientnet') or config['model_name'].startswith('vit'):\n",
    "                # pretty_layer_name = '%s_%02d' % (\n",
    "                #     bottleneck['layer_name'].split('_')[0],\n",
    "                #     int(bottleneck['layer_name'].split('_')[-1])\n",
    "                # )\n",
    "                pretty_layer_name = bottleneck['layer_name']\n",
    "            else:\n",
    "                pretty_layer_name = bottleneck['layer_name']\n",
    "            head_model = nn.Sequential(*list(model.features[:(bottleneck['block_number'] + 1)]))\n",
    "            \n",
    "            batch_table[batch_size][pretty_layer_name] = {\n",
    "                'compression': bottleneck['compression'],\n",
    "                'head': get_inference_time(head_model, batch_size, device=config['processors']['weak']),\n",
    "            }\n",
    "            \n",
    "            input_shape = (batch_size, 3, config['image_size'], config['image_size'])\n",
    "            # 入力は画像データではなくすべて1のデータ\n",
    "            input_data = torch.ones(input_shape, device=config['processors']['weak'])  \n",
    "            edge_output = head_model(input_data)\n",
    "            edge_output = edge_output.to(config['processors']['strong'])\n",
    "            # 元のモデルにFlattenとclassifierついてないの？\n",
    "            server_model_layers = list(model.features[(bottleneck['block_number'] + 1):]) + [model.pool] +[nn.Flatten()]\n",
    "            server_model_layers += list(model.classifier)\n",
    "\n",
    "            \n",
    "            tail_model = nn.Sequential(*server_model_layers)\n",
    "            batch_table[batch_size][pretty_layer_name]['tail'] = get_inference_time(\n",
    "                tail_model,\n",
    "                batch_size, device=config['processors']['strong'], intermediate=edge_output\n",
    "            )\n",
    "\n",
    "            save_batch_table(batch_table, config)\n",
    "        print()  # newline ←これなに？\n",
    "    return batch_table\n",
    "\n",
    "# これいつ使う？何用？\n",
    "def split_efficientnet_model(model, split_layer, edge_device, server_device):\n",
    "    edge_model = nn.Sequential(*list(model.features[:split_layer])).to(edge_device)\n",
    "    server_model_layers = list(model.features[split_layer:]) + [model.pool] +[nn.Flatten()]\n",
    "    server_model_layers += list(model.classifier)\n",
    "    server_model = nn.Sequential(*server_model_layers).to(server_device)\n",
    "    return edge_model, server_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量子化しても送る時のbit幅は変わらない→量子化しても通信時間は変わらない\n",
    "def get_load(compression, batch_size, config, full_offloading):\n",
    "    # 3 channels\n",
    "    load = batch_size * (config['image_size'] ** 2) * 3 * compression\n",
    "    if not full_offloading:\n",
    "        # load *= 4  # float32\n",
    "        load *= 1 # int8をデフォルトに\n",
    "    return load\n",
    "\n",
    "def fix_legend_name(name):\n",
    "    if name == 'whole_device':\n",
    "        return 'No Offloading'\n",
    "    elif name == 'whole_edge':\n",
    "        return 'Full Offloading'\n",
    "    else:\n",
    "        # return 'Split at\\n%s' % name.split('/')[-1]\n",
    "        return name\n",
    "\n",
    "def create_inference_plots(batch_table, config, create_individual=True):\n",
    "    split_points = list(batch_table[list(batch_table.keys())[0]].keys()) #←なにこれ？\n",
    "    # print(split_points)\n",
    "    bandwidths = np.arange(config['min_bandwidth'], config['max_bandwidth'], config['bandwidth_step'])\n",
    "    best_splits = {}\n",
    "    gains = {}\n",
    "    inference_times__all = []  #Gainのグラフを作るためのリスト 各バッチサイズの最小推論時間をいれる\n",
    "    for batch_size in batch_table.keys():\n",
    "        if create_individual:\n",
    "            plt.figure(figsize=FIGURE_SIZE)\n",
    "        entry = batch_table[batch_size]\n",
    "        inference_times_list = []\n",
    "        for i, split_point in enumerate(split_points):\n",
    "            if split_point == 'whole_device':\n",
    "                inference_times = np.repeat(entry[split_point], bandwidths.shape[0]) \n",
    "                if create_individual:\n",
    "                    plt.ylim(0, entry[split_point] * 2)\n",
    "            elif split_point == 'whole_edge':\n",
    "                load = get_load(1, int(batch_size), config, True)\n",
    "                inference_times = entry[split_point] + load / bandwidths * 1000  # in milliseconds\n",
    "            else:\n",
    "                load = get_load(entry[split_point]['compression'], int(batch_size), config, False)\n",
    "                inference_times = entry[split_point]['head'] + entry[split_point]['tail'] + load / bandwidths * 1000  # in milliseconds\n",
    "            linestyle = PLOT_LINESTYLES[i % len(PLOT_LINESTYLES)]\n",
    "            if create_individual:\n",
    "                plt.plot(\n",
    "                    bandwidths / 10 ** 6,\n",
    "                    inference_times,\n",
    "                    label=fix_legend_name(split_point),\n",
    "                    linestyle=linestyle\n",
    "                )\n",
    "            inference_times_list.append(inference_times)\n",
    "        if create_individual:\n",
    "            plt.xlabel('Data Rate (MBps)')\n",
    "            plt.ylabel('Inference Time (ms)')\n",
    "            plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "            save_path = os.path.join(INFERENCE_PLOT_DIR, '%s_%s_%s_v%d.png' % (\n",
    "                config['model_name'],\n",
    "                batch_size,\n",
    "                config['processors']['weak'].replace('/', ''),\n",
    "                VERSION\n",
    "            ))\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        best_split = np.argmin(np.array(inference_times_list), axis=0)\n",
    "        best_splits[batch_size] = best_split\n",
    "        inference_times__all.append(np.min(np.array(inference_times_list), axis=0))\n",
    "        gains[batch_size] = {}\n",
    "        for split_point_index, split_point in enumerate(split_points):\n",
    "            absolute_diff = inference_times_list[split_point_index] - np.min(np.array(inference_times_list), axis=0)\n",
    "            relative_diff = absolute_diff / inference_times_list[split_point_index]\n",
    "            diff_percent = relative_diff * 100\n",
    "            gains[batch_size][split_point] = np.clip(\n",
    "                diff_percent,\n",
    "                None,\n",
    "                np.mean(diff_percent)\n",
    "            )\n",
    "    if not os.path.exists(\"inference_time\"):\n",
    "        os.makedirs(\"inference_time\")\n",
    "    save_path = os.path.join(\"inference_time\", '%s_%s.npy' % (\n",
    "        config['model_name'],\n",
    "        config['graph_title'],\n",
    "    ))\n",
    "    np.save(save_path, inference_times__all) \n",
    "    \n",
    "    total_points = 0\n",
    "    useful_split_points = 0\n",
    "    color_mapped_values = []\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "    # 確認\n",
    "    # print(split_points)\n",
    "    # print(best_splits)\n",
    "    \n",
    "    for batch_size, best_split in sorted(best_splits.items(), key=lambda x: int(x[0])):\n",
    "        color_mapped_values.append([])\n",
    "        for bandwidth_index, entry in enumerate(best_split):\n",
    "            for split_point_index, split_point in enumerate(split_points):\n",
    "                if entry == split_point_index:\n",
    "                    color_mapped_values[-1].append(split_point_index)\n",
    "                    total_points += 1\n",
    "                    # print(split_point)\n",
    "                    if split_point != 'whole_edge' and split_point != 'whole_device':\n",
    "                        useful_split_points += 1\n",
    "                    break\n",
    "    print(color_mapped_values)\n",
    "    used_split_indices = np.sort(np.unique(np.array(color_mapped_values))).tolist()\n",
    "    print(used_split_indices)\n",
    "    used_colors = [PLOT_COLORS[used_split_index] for used_split_index in used_split_indices]\n",
    "    print(used_colors)\n",
    "    color_map = ListedColormap(used_colors)\n",
    "    # print(color_map)\n",
    "\n",
    "    # replace distinct values with their index of discovery\n",
    "    previous_shape = np.array(color_mapped_values).shape\n",
    "    _, color_mapped_values = np.unique(np.array(color_mapped_values), return_inverse=True)\n",
    "    color_mapped_values = np.reshape(color_mapped_values, previous_shape)\n",
    "    # colormesh = plt.pcolormesh(color_mapped_values, cmap=color_map)\n",
    "    colormesh = plt.pcolormesh(color_mapped_values, cmap=color_map, edgecolors='w', linewidth=0.5)\n",
    "    # legend\n",
    "    cbar = plt.colorbar(colormesh)\n",
    "    cbar.ax.get_yaxis().set_ticks([])\n",
    "    max_value = np.amax(color_mapped_values)\n",
    "    for j, used_split_index in enumerate(used_split_indices):\n",
    "        cbar.ax.text(\n",
    "            1.2,  # カラーバーからの相対位置\n",
    "            j / len(used_split_indices) + 0.5 / len(used_split_indices),\n",
    "            fix_legend_name(split_points[used_split_index]),\n",
    "            ha='left',\n",
    "            va='center',\n",
    "            transform=cbar.ax.transAxes  \n",
    "        )\n",
    "    #################################################\n",
    "    plt.xlabel('Data Rate (MBps)')\n",
    "    plt.ylabel('Batch Size')\n",
    "    # plt.title(r'(c) Ours ($\\lambda = 1 \\times 10^{-4}$)', fontsize=25, weight=\"bold\")\n",
    "    plt.title(config[\"graph_title\"], fontsize=25, weight=\"bold\")\n",
    "    save_path = os.path.join(INFERENCE_PLOT_DIR, '%s_all_%s_v%d.svg' % (\n",
    "        config['model_name'],\n",
    "        config['processors']['weak'].replace('/', ''),\n",
    "        VERSION\n",
    "    ))\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    # 何を確認する用か実行して確認\n",
    "    print('Percent of scenarios where split computing is useful: %.2f%% (%d/%d)' % (\n",
    "        useful_split_points / total_points * 100,\n",
    "        useful_split_points,\n",
    "        total_points\n",
    "    ))\n",
    "# print(\"gains:{}\",format(gains))\n",
    "    for split_point in split_points:\n",
    "        heatmap_data = []\n",
    "        for batch_size in sorted(gains.keys(), key=lambda x: int(x)):\n",
    "            heatmap_data.append(gains[batch_size][split_point])\n",
    "        heatmap_data = list(heatmap_data)\n",
    "        fig, main_ax = plt.subplots()\n",
    "        fig.set_size_inches(FIGURE_SIZE[0], FIGURE_SIZE[1])\n",
    "        # ax = sns.heatmap(np.array(heatmap_data), cbar_kws={'label': 'Gain %'}, ax=main_ax)\n",
    "        ax = sns.heatmap(np.array(heatmap_data), cbar_kws={'label': 'Gain %'}, ax=main_ax, linewidths=0.1, linecolor='w')\n",
    "        ax.set_xlabel('Data Rate (MBps)')\n",
    "        ax.set_ylabel('Batch Size')\n",
    "        ax.invert_yaxis()\n",
    "        save_path = os.path.join(INFERENCE_PLOT_DIR, '%s_gain_over_%s_%s_v%d.svg' % (\n",
    "            config['model_name'],\n",
    "            split_point.replace('/', ''),  # ViT has / in block names\n",
    "            config['processors']['weak'].replace('/', ''),\n",
    "            VERSION\n",
    "        ))\n",
    "        ax.figure.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "#batch_tableがすでに作られてる場合動かないので注意 \n",
    "# def run_experiment(config, recreate=False):\n",
    "#     if recreate or not os.path.exists(get_batch_table_path(config)):\n",
    "#         print(\"run expereiment\")\n",
    "#         batch_table = create_batch_table(config)\n",
    "\n",
    "# def run_experimentじゃダメなの？\n",
    "def create_baseline_table(config):     # inference timeのテーブルを作成する時に使用する\n",
    "    if 'baseline' in config[\"model_name\"]:\n",
    "        batch_table = create_batch_table(config)\n",
    "    else:\n",
    "        raise Exception(\"モデルにbaselineが指定されていません\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_time_only(batch_table,config):\n",
    "    split_points = list(batch_table[list(batch_table.keys())[0]].keys())\n",
    "    bandwidths = np.arange(config['min_bandwidth'], config['max_bandwidth'], config['bandwidth_step'])\n",
    "    \n",
    "    for batch_size in config[\"batch_sizes\"]:\n",
    "        inference_times_list = []\n",
    "        plt.figure(figsize=FIGURE_SIZE)\n",
    "        entry = batch_table[str(batch_size)]\n",
    "        for i, split_point in enumerate(split_points):\n",
    "            # No Offloading(int8)\n",
    "            if split_point == 'whole_device':\n",
    "                whole_device_inference = np.repeat(entry['whole_device'], bandwidths.shape[0]) \n",
    "                # inference_times_list.append(whole_device_inference)\n",
    "                plt.ylim(0, entry[split_point] * 2)\n",
    "            # full_offloading(int8)\n",
    "            elif split_point == 'whole_edge':\n",
    "                load = get_load(1, int(batch_size), config, True)\n",
    "                whole_edge_inference = entry[split_point] + load / bandwidths * 1000\n",
    "                # inference_times_list.append(whole_edge_inference)\n",
    "            # DSC(ours)\n",
    "            else:\n",
    "                load = get_load(entry[split_point]['compression'], int(batch_size), config, False)\n",
    "                inference_times_list.append(entry[split_point]['head'] + entry[split_point]['tail'] + load / bandwidths * 1000)  # in milliseconds\n",
    "        dsc_inference = []\n",
    "        # dsc_inference_sp =[]\n",
    "        for i in range(bandwidths.shape[0]):\n",
    "            dsc_inference.append(min([bandwidth_time[i] for bandwidth_time in inference_times_list]))\n",
    "            \n",
    "            # dsc_inference_sp.append(split_points[np.argmin([bandwidth_time[i] for bandwidth_time in inference_times_list])])\n",
    "        \n",
    "        \n",
    "        plt.plot(\n",
    "            bandwidths / 10 ** 6,\n",
    "            whole_device_inference,\n",
    "            label=\"whole_device(int8)\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            bandwidths / 10 ** 6,\n",
    "            whole_edge_inference,\n",
    "            label=\"whole_server(int8)\",\n",
    "            linestyle='-.'\n",
    "        )\n",
    "        plt.plot(\n",
    "            bandwidths / 10 ** 6,\n",
    "            dsc_inference,\n",
    "            label=\"Ours(λ=0.01)\",\n",
    "            linestyle='-'\n",
    "        )\n",
    "        plt.title(f'EfficientNet_b0 batch_size:{batch_size}')\n",
    "        plt.xlabel('Data Rate (MBps)')\n",
    "        plt.ylabel('Inference Time (ms)')\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "        plt.grid()\n",
    "        \n",
    "        save_dir = f'./{INFERENCE_PLOT_DIR_MODIFIED}/{config[\"model_name\"]}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, 'inference_time_%s.png' % (\n",
    "                batch_size\n",
    "            ))\n",
    "        # check\n",
    "        # print(np.round(dsc_inference,2))\n",
    "        # print(np.round(whole_edge_inference,2))\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'processors': {\n",
    "        'weak': 'cuda:1',\n",
    "        'strong': 'cuda:0',\n",
    "    },\n",
    "    'model_name': 'quanteffnet_cfg_2468',\n",
    "    'arch_path' : \"/EdMIPS/arch_output/mixeffnet_b0_w2468a2468_100_csd0.01_modified/arch_model_best.pth.tar\",\n",
    "    'image_size': 224,\n",
    "    'batch_sizes': list(range(1, 31)),\n",
    "    'max_bandwidth': 128 * 10 ** 6,  # Bytes per second\n",
    "    'min_bandwidth': 1 * 10 ** 6,  # Bytes per second\n",
    "    'bandwidth_step': 1 * 10 ** 6,  # Bytes per second\n",
    "    'graph_title': 'effcientnet_b0_w2468a2468_forlossynet ($\\lambda = 0.01$)',\n",
    "}\n",
    "\n",
    "\n",
    "# config = {\n",
    "#     'processors': {\n",
    "#         'weak': 'cuda:1',\n",
    "#         'strong': 'cuda:0',\n",
    "#     },\n",
    "#     'model_name': 'quanteffnet_cfg_2468_b3',\n",
    "#     'arch_path' : \"/EdMIPS/arch_output/mixeffnet_b3_w2468a2468_100_csd0.01_modified_v2/arch_model_best.pth.tar\",\n",
    "#     'image_size': 300,\n",
    "#     'batch_sizes': list(range(1, 16)),\n",
    "#     'max_bandwidth': 128 * 10 ** 6,  # Bytes per second\n",
    "#     'min_bandwidth': 1 * 10 ** 6,  # Bytes per second\n",
    "#     'bandwidth_step': 1 * 10 ** 6,  # Bytes per second\n",
    "#     'graph_title': 'Ours ($\\lambda = 0.01$)',\n",
    "# }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archas: [6, 2, 4, 8, 6, 4, 6, 8, 6, 6, 4, 8, 4, 6, 2, 2, 4, 6, 8, 2, 4, 6, 4, 6, 4, 8, 6, 4, 6, 2, 2, 2, 2, 6, 2, 2, 6, 2, 6, 4, 4, 6, 4, 4, 2, 2, 2, 2, 6, 2, 2, 4, 2, 6, 2, 4, 4, 2, 6, 2, 4, 2, 2, 4, 4, 6, 6, 4, 6, 2, 4, 4, 2, 6, 2, 4, 4, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 6, 6, 4, 4, 4, 4, 4, 6, 6, 4, 2, 2, 6, 6, 4, 2, 4, 6, 6, 4, 2, 4, 6, 2, 2, 2, 2, 6, 2, 4, 4, 4, 4, 6, 2, 4, 4, 2, 8]\n",
      "archws: [8, 8, 2, 8, 4, 8, 8, 4, 8, 8, 2, 2, 8, 2, 2, 2, 4, 2, 2, 2, 8, 8, 2, 8, 8, 8, 2, 8, 4, 2, 6, 2, 6, 4, 2, 8, 8, 2, 8, 8, 8, 2, 8, 2, 2, 6, 8, 2, 4, 2, 6, 8, 2, 2, 2, 6, 4, 2, 2, 2, 4, 8, 2, 8, 8, 8, 8, 8, 2, 2, 6, 6, 2, 2, 2, 8, 2, 2, 2, 2, 4, 2, 2, 2, 2, 6, 6, 2, 8, 2, 8, 8, 8, 8, 2, 4, 6, 8, 8, 2, 4, 2, 8, 8, 2, 4, 2, 8, 8, 2, 2, 2, 8, 8, 2, 2, 2, 8, 8, 4, 8, 4, 8, 2, 2, 4, 4, 2, 8]\n",
      "Encountered BasicBlock at features.0\n",
      "[3, 6, 9, 17, 19, 23]\n",
      "[0, 4, 7, 10, 18, 20, 24]\n"
     ]
    }
   ],
   "source": [
    "# ここから下のコードは何をやってるの？\n",
    "MODEL_NAME = config['model_name']  # ここでモデル名を取得\n",
    "ARCH_NAME = config['graph_title']  # ここでモデル名を取得\n",
    "INFERENCE_PLOT_DIR = os.path.join('inference_plot', MODEL_NAME, ARCH_NAME, str(VERSION))\n",
    "if not os.path.exists(INFERENCE_PLOT_DIR):\n",
    "    os.makedirs(INFERENCE_PLOT_DIR)\n",
    "model, act_bits = get_model(config)\n",
    "# print(model.features)\n",
    "natural_bottlenecks = get_natural_bottlenecks(model, config[\"image_size\"], act_bits=act_bits, compressive_only=True)\n",
    "\n",
    "print([bottleneck['block_number'] for bottleneck in natural_bottlenecks])\n",
    "# ここの+1なに？\n",
    "block_numbers = [0] + [(bottleneck['block_number']+1) for bottleneck in natural_bottlenecks]\n",
    "print(block_numbers)\n",
    "\n",
    "colors_list = [\n",
    "    'blue', 'green', 'red', 'teal', 'magenta',\n",
    "    'yellow', 'black', 'orange', 'purple', 'brown',\n",
    "    'pink', 'gray', 'olive', 'lime', 'indigo',\n",
    "    'gold', 'darkblue', 'darkgreen', 'coral', 'skyblue',\n",
    "    'lavender', 'beige', 'turquoise', 'plum', 'salmon','cyan'\n",
    "]\n",
    "PLOT_COLORS = [colors_list[i] for i in block_numbers]\n",
    "# print(PLOT_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BasicCNNBlock(\n",
      "  (conv): Conv2d(3, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(38, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (silu): SiLU()\n",
      ")\n",
      "1 InvertedResidualBlock(\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=38, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(38, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(9, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(38, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2 InvertedResidualBlock(\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(20, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(5, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "3 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(20, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(120, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(5, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(120, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "4 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(192, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(8, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "5 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(192, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(8, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "6 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(192, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(8, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "7 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(48, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "8 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(48, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "9 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(48, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "10 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(576, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(24, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "11 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(576, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(24, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "12 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(576, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(24, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "13 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(576, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(24, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "14 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(576, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(24, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "15 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(136, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(816, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(34, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "16 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(136, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(816, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(34, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "17 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(136, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(816, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(34, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "18 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(136, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(816, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(34, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "19 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(136, 816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(816, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(34, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "20 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "21 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "22 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "23 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "24 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "25 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(232, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(1392, 388, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(388, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "26 InvertedResidualBlock(\n",
      "  (expand_conv): CNNBlock(\n",
      "    (cnn): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(388, 2328, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn): BatchNorm2d(2328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (cnn): QuantActivConv2d(\n",
      "        (activ): HWGQ()\n",
      "        (conv): QuantConv2d(2328, 2328, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2328, bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(2328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (silu): SiLU()\n",
      "    )\n",
      "    (1): SqueezeExcitation(\n",
      "      (se): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(2328, 97, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): SiLU()\n",
      "        (3): QuantActivConv2d(\n",
      "          (activ): HWGQ()\n",
      "          (conv): QuantConv2d(97, 2328, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): QuantActivConv2d(\n",
      "      (activ): HWGQ()\n",
      "      (conv): QuantConv2d(2328, 388, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(388, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "27 CNNBlock(\n",
      "  (cnn): QuantActivConv2d(\n",
      "    (activ): HWGQ()\n",
      "    (conv): QuantConv2d(388, 1549, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (bn): BatchNorm2d(1549, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (silu): SiLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, module in enumerate(model.features):\n",
    "    print(i, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'whole_device': 115.05890115666641, 'whole_edge': 33.403415089999655, 'blocks_0': {'compression': 0.6666666666666666, 'head': 0.4038302233334434, 'tail': 34.097693313333366}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 3.374997586666571, 'tail': 30.076414529999813}, 'blocks_2': {'compression': 0.125, 'head': 10.962852356666795, 'tail': 28.343934909999764}, 'blocks_3': {'compression': 0.125, 'head': 16.692602493333577, 'tail': 29.61196232666642}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 21.212122013333403, 'tail': 25.124492406666832}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 25.445428483333593, 'tail': 22.210260236666574}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 29.815285576666685, 'tail': 20.545710316666828}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 33.80711141666666, 'tail': 17.86688488999971}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 38.88537258666664, 'tail': 15.531997696666622}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 44.53172772333346, 'tail': 14.058842543333487}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 50.70077023999981, 'tail': 13.234629463333173}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 57.21657424, 'tail': 11.053665103333591}, 'blocks_12': {'compression': 0.015625, 'head': 63.07803982333325, 'tail': 9.59451106333328}, 'blocks_13': {'compression': 0.015625, 'head': 74.20034685666678, 'tail': 6.576885050000101}, 'blocks_14': {'compression': 0.015625, 'head': 87.80344027333322, 'tail': 5.001203496666828}, 'blocks_15': {'compression': 0.015625, 'head': 86.54637590666691, 'tail': 2.4805412433333154}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 109.80848462000002, 'tail': 0.6516142533333399}}, '2': {'whole_device': 126.1887470166668, 'whole_edge': 30.267452260000027, 'blocks_0': {'compression': 0.6666666666666666, 'head': 0.8351763499998318, 'tail': 29.53243850666695}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 6.958177260000109, 'tail': 28.65109726999966}, 'blocks_2': {'compression': 0.125, 'head': 17.933591796666708, 'tail': 26.018345290000298}, 'blocks_3': {'compression': 0.125, 'head': 26.089713006666294, 'tail': 25.347577789999985}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 31.851630679999897, 'tail': 23.296196290000353}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 37.23283285666639, 'tail': 21.25168413333313}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 41.84573273333323, 'tail': 19.767864676666704}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 46.43485177333332, 'tail': 17.75841555333348}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 51.33729455333272, 'tail': 14.86251091999975}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 56.10159230999973, 'tail': 13.006460536666964}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 63.117748499999685, 'tail': 14.036750566666948}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 70.58570776666633, 'tail': 9.836930933333102}, 'blocks_12': {'compression': 0.015625, 'head': 79.2964404700001, 'tail': 8.502838540000539}, 'blocks_13': {'compression': 0.015625, 'head': 93.0349554033334, 'tail': 6.116451533333323}, 'blocks_14': {'compression': 0.015625, 'head': 104.68589239000039, 'tail': 4.359873093333135}, 'blocks_15': {'compression': 0.015625, 'head': 112.38179561, 'tail': 2.9217301166666707}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 121.90041520000023, 'tail': 0.7327213033333161}}, '3': {'whole_device': 144.19287482333326, 'whole_edge': 30.990268639999762, 'blocks_0': {'compression': 0.6666666666666666, 'head': 0.9837279499993201, 'tail': 31.02369211666731}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 9.085277966666277, 'tail': 29.197473879999812}, 'blocks_2': {'compression': 0.125, 'head': 11.4964712733331, 'tail': 27.29786379000037}, 'blocks_3': {'compression': 0.125, 'head': 17.37994143333405, 'tail': 24.788130066666174}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 24.028494406666898, 'tail': 23.33432721666668}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 33.65462681666713, 'tail': 20.901578813333494}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 54.79666091666635, 'tail': 23.54306559666611}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 60.00490888666642, 'tail': 17.465318816666695}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 65.46620253666636, 'tail': 15.759823943333231}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 74.27969074999965, 'tail': 14.97392907333354}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 82.17193217666666, 'tail': 11.888058730000163}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 91.24007226333333, 'tail': 10.373172910000601}, 'blocks_12': {'compression': 0.015625, 'head': 94.24904696333367, 'tail': 8.23058742999971}, 'blocks_13': {'compression': 0.015625, 'head': 106.25419949000009, 'tail': 6.070771100000153}, 'blocks_14': {'compression': 0.015625, 'head': 119.26071808000037, 'tail': 4.041580660000363}, 'blocks_15': {'compression': 0.015625, 'head': 128.9734309299994, 'tail': 2.759915630000099}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 141.34648106333393, 'tail': 0.7965196600002855}}, '4': {'whole_device': 160.79486920666645, 'whole_edge': 30.38587956333307, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.2075639866664762, 'tail': 31.006900603333634}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 5.5599517866668675, 'tail': 30.130576663333006}, 'blocks_2': {'compression': 0.125, 'head': 13.825839830000556, 'tail': 29.431097706666755}, 'blocks_3': {'compression': 0.125, 'head': 21.488422809999673, 'tail': 27.10003754333381}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 27.67685829666637, 'tail': 23.29841219666681}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 36.64986321333269, 'tail': 21.98350588666623}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 42.550190850000334, 'tail': 19.761141059999925}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 46.910772713332946, 'tail': 18.07931879666588}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 81.18084369000069, 'tail': 15.42318853333351}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 88.40812390666694, 'tail': 13.195841503332606}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 96.6986651499989, 'tail': 11.53235481666646}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 105.20957064999948, 'tail': 9.867617196665984}, 'blocks_12': {'compression': 0.015625, 'head': 113.91522552666629, 'tail': 7.537400953333417}, 'blocks_13': {'compression': 0.015625, 'head': 124.34939292999994, 'tail': 8.015970743334341}, 'blocks_14': {'compression': 0.015625, 'head': 136.51941337333332, 'tail': 4.736012536667053}, 'blocks_15': {'compression': 0.015625, 'head': 154.06049261000135, 'tail': 2.9001427299999705}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 164.54011330333287, 'tail': 0.7358514133329663}}, '5': {'whole_device': 185.56853930000065, 'whole_edge': 30.86761063666624, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.3929160699990462, 'tail': 31.86836590333314}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 6.373559410000477, 'tail': 29.64082188999934}, 'blocks_2': {'compression': 0.125, 'head': 15.216887903332767, 'tail': 26.426530850000443}, 'blocks_3': {'compression': 0.125, 'head': 23.31265043000106, 'tail': 24.617780229999276}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 30.279095030000462, 'tail': 22.614854236665753}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 39.13833992666544, 'tail': 20.769861049999843}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 45.834277176666845, 'tail': 19.12662526333255}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 52.49291588333259, 'tail': 17.07144628333329}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 94.7399734999999, 'tail': 16.616490836666646}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 102.72277673000038, 'tail': 15.255971513332346}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 116.09939490999902, 'tail': 12.11083035666737}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 127.24698500999995, 'tail': 10.474647880000703}, 'blocks_12': {'compression': 0.015625, 'head': 132.02300862666712, 'tail': 7.752818296667101}, 'blocks_13': {'compression': 0.015625, 'head': 146.24653646999982, 'tail': 6.005417159999524}, 'blocks_14': {'compression': 0.015625, 'head': 156.11498033000012, 'tail': 4.447365869999278}, 'blocks_15': {'compression': 0.015625, 'head': 170.20446509666576, 'tail': 2.4367811499996606}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 181.08670881333333, 'tail': 0.7811787999996038}}, '6': {'whole_device': 206.8975400666659, 'whole_edge': 32.787212816667, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.1329373866662231, 'tail': 32.468214016666934}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 6.991146166665203, 'tail': 30.424885883333747}, 'blocks_2': {'compression': 0.125, 'head': 17.631211670000084, 'tail': 28.489070073333096}, 'blocks_3': {'compression': 0.125, 'head': 26.03998596999948, 'tail': 25.766537119999764}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 33.773864736666226, 'tail': 23.231125676666124}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 43.802947483333504, 'tail': 21.673207079999578}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 51.59275627666678, 'tail': 20.050617023333267}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 56.824055436666946, 'tail': 17.968394096666692}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 62.20041970333265, 'tail': 16.22941227999945}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 68.9439434533339, 'tail': 14.529761026666772}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 78.18424417666697, 'tail': 11.79984018999979}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 89.87391194333213, 'tail': 12.148978359999395}, 'blocks_12': {'compression': 0.015625, 'head': 93.83618719333299, 'tail': 8.06558846000068}, 'blocks_13': {'compression': 0.015625, 'head': 166.20441866333294, 'tail': 6.3431130066677115}, 'blocks_14': {'compression': 0.015625, 'head': 180.3612664866675, 'tail': 4.583085870000711}, 'blocks_15': {'compression': 0.015625, 'head': 189.64855980999954, 'tail': 2.791510319999967}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 201.20355430333348, 'tail': 0.7377532099993308}}, '7': {'whole_device': 142.56694529000015, 'whole_edge': 31.237924743333373, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.41488658999909, 'tail': 31.587330323333543}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 7.37072777333348, 'tail': 33.85065264666688}, 'blocks_2': {'compression': 0.125, 'head': 18.931946210000206, 'tail': 32.71513939666571}, 'blocks_3': {'compression': 0.125, 'head': 28.725070246667503, 'tail': 31.263022243333577}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 37.471008430000744, 'tail': 24.033492603333194}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 48.89943503666625, 'tail': 24.826965346666537}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 63.39501594000012, 'tail': 20.33243663333451}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 63.95661191666628, 'tail': 18.640455356665672}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 70.79815652333309, 'tail': 16.46174580000055}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 75.76193830000041, 'tail': 14.373448883332761}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 86.19180507333265, 'tail': 12.570846286666892}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 133.49293304666693, 'tail': 10.013109859999835}, 'blocks_12': {'compression': 0.015625, 'head': 103.31710837000021, 'tail': 8.049028520000926}, 'blocks_13': {'compression': 0.015625, 'head': 182.797036533334, 'tail': 5.912507823333423}, 'blocks_14': {'compression': 0.015625, 'head': 127.93851837999986, 'tail': 4.737685646665947}, 'blocks_15': {'compression': 0.015625, 'head': 133.6240303166657, 'tail': 3.066349476666801}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 145.52254175333474, 'tail': 0.8223833400006697}}, '8': {'whole_device': 154.73512497666889, 'whole_edge': 32.11837467666859, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.3942055933330266, 'tail': 31.072896596667004}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 8.112238336664934, 'tail': 29.876393846664843}, 'blocks_2': {'compression': 0.125, 'head': 21.084212926665106, 'tail': 27.589291396667857}, 'blocks_3': {'compression': 0.125, 'head': 32.109663530000034, 'tail': 26.844940249999734}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 41.47876620333288, 'tail': 23.430713366666776}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 53.323308530001064, 'tail': 21.668248516668122}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 61.52975756333338, 'tail': 19.87714959666543}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 68.02033998333476, 'tail': 17.72922763333251}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 74.2949287700018, 'tail': 15.850181316664019}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 81.97500029000062, 'tail': 16.71841120333132}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 92.82257460000135, 'tail': 12.773206323333094}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 108.56553011333138, 'tail': 10.377958380001171}, 'blocks_12': {'compression': 0.015625, 'head': 114.87495218000126, 'tail': 7.973659886668733}, 'blocks_13': {'compression': 0.015625, 'head': 123.37241373999859, 'tail': 6.782839110001078}, 'blocks_14': {'compression': 0.015625, 'head': 132.773180326667, 'tail': 4.307964153334372}, 'blocks_15': {'compression': 0.015625, 'head': 141.9594743866643, 'tail': 3.3313281933321073}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 151.41795267333086, 'tail': 0.929162646665039}}, '9': {'whole_device': 168.16287912666667, 'whole_edge': 39.46960971666765, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.8153943833325077, 'tail': 38.29932381999849}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 8.82746764666687, 'tail': 29.280077000000045}, 'blocks_2': {'compression': 0.125, 'head': 22.870752669999394, 'tail': 26.440508310000343}, 'blocks_3': {'compression': 0.125, 'head': 35.776396653333606, 'tail': 30.08933815666751}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 46.17185385666744, 'tail': 23.560206436668523}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 58.88661895999879, 'tail': 24.15760300000026}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 69.01208128666742, 'tail': 22.54970005333538}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 73.63834869999968, 'tail': 17.366813413333755}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 83.1789118400017, 'tail': 15.067789040000813}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 89.37207511333327, 'tail': 15.179496033333635}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 100.40866435333253, 'tail': 11.619076420001875}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 113.66101293333183, 'tail': 9.505744306667717}, 'blocks_12': {'compression': 0.015625, 'head': 123.59801973333258, 'tail': 9.77330386000176}, 'blocks_13': {'compression': 0.015625, 'head': 130.87626334666612, 'tail': 6.258160226664889}, 'blocks_14': {'compression': 0.015625, 'head': 146.1232210099994, 'tail': 4.5432340633336326}, 'blocks_15': {'compression': 0.015625, 'head': 156.9619007033331, 'tail': 3.072660033334008}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 165.59910647333407, 'tail': 1.0270848133344164}}, '10': {'whole_device': 173.49722306999865, 'whole_edge': 31.886482493334068, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.7496445166671037, 'tail': 32.13178985999851}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 9.54554642333278, 'tail': 29.893718609998054}, 'blocks_2': {'compression': 0.125, 'head': 25.072273780000007, 'tail': 26.59193034666714}, 'blocks_3': {'compression': 0.125, 'head': 38.942629503332384, 'tail': 24.924379646666544}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 49.86088012666793, 'tail': 23.460743496668027}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 63.64569506999943, 'tail': 27.318226653333113}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 72.90494576000128, 'tail': 18.94228452999717}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 79.972266616669, 'tail': 20.964395190000385}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 88.33085538666637, 'tail': 15.871448140002638}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 97.00966690000011, 'tail': 15.11103376333267}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 107.22230700666537, 'tail': 13.720820236664318}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 122.05437411666632, 'tail': 9.36670007333305}, 'blocks_12': {'compression': 0.015625, 'head': 127.93746734666759, 'tail': 8.620776133332887}, 'blocks_13': {'compression': 0.015625, 'head': 137.97500257666496, 'tail': 5.75851494999976}, 'blocks_14': {'compression': 0.015625, 'head': 153.39610050666428, 'tail': 4.512629789999967}, 'blocks_15': {'compression': 0.015625, 'head': 160.20807939000105, 'tail': 2.6873489566666344}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 173.01425383333176, 'tail': 1.032767030001196}}, '11': {'whole_device': 191.8725585566669, 'whole_edge': 34.65506510666577, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.6654473366664508, 'tail': 32.95553857000111}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 10.539397960001224, 'tail': 29.71178486000099}, 'blocks_2': {'compression': 0.125, 'head': 27.113173416667752, 'tail': 26.881758536665075}, 'blocks_3': {'compression': 0.125, 'head': 40.974804863332494, 'tail': 25.35413859000073}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 52.931304526667496, 'tail': 24.359298266666276}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 68.23530525000024, 'tail': 20.858876610000152}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 78.98122746666863, 'tail': 18.658868233333123}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 86.62499289999991, 'tail': 17.689700290002293}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 93.18762264666475, 'tail': 20.198571176667123}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 101.29556588666674, 'tail': 13.728877916664715}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 116.7456516200006, 'tail': 11.631021830001677}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 129.35583897666828, 'tail': 10.480459276665595}, 'blocks_12': {'compression': 0.015625, 'head': 137.42511577666846, 'tail': 7.665728189998239}, 'blocks_13': {'compression': 0.015625, 'head': 154.64951821666546, 'tail': 6.0570955366650505}, 'blocks_14': {'compression': 0.015625, 'head': 164.10375508333345, 'tail': 4.688489546664035}, 'blocks_15': {'compression': 0.015625, 'head': 178.9719155833336, 'tail': 2.7189136699992864}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 186.36751051333098, 'tail': 1.1221564900006342}}, '12': {'whole_device': 197.05411766333478, 'whole_edge': 33.030973503333975, 'blocks_0': {'compression': 0.6666666666666666, 'head': 1.799393813334973, 'tail': 34.46246023000034}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 11.26887465999971, 'tail': 33.11877332333097}, 'blocks_2': {'compression': 0.125, 'head': 28.99325870666568, 'tail': 30.42228356999961}, 'blocks_3': {'compression': 0.125, 'head': 43.62175916333399, 'tail': 24.83003624999886}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 57.7632837166675, 'tail': 22.792771046664107}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 73.06051282666583, 'tail': 20.43448713999775}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 84.08002620333112, 'tail': 19.4994881900008}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 91.0724007133346, 'tail': 17.249523609998505}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 100.53174694333089, 'tail': 15.192549219997696}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 108.57303496999823, 'tail': 18.08128346666611}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 121.31818651999916, 'tail': 14.155171270000816}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 137.31784918666563, 'tail': 10.307932669999596}, 'blocks_12': {'compression': 0.015625, 'head': 147.48021667999942, 'tail': 8.814343146668762}, 'blocks_13': {'compression': 0.015625, 'head': 161.99059175999838, 'tail': 6.409593426666712}, 'blocks_14': {'compression': 0.015625, 'head': 170.48959392999978, 'tail': 4.35720677000063}, 'blocks_15': {'compression': 0.015625, 'head': 180.8886971200021, 'tail': 2.759364609998253}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 189.61406963000022, 'tail': 0.9070720666659327}}, '13': {'whole_device': 192.95985891666837, 'whole_edge': 33.127780773335566, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.1142980333327914, 'tail': 33.113831280000646}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 11.753110829998452, 'tail': 31.174761689999286}, 'blocks_2': {'compression': 0.125, 'head': 31.32705100666802, 'tail': 28.47577783000209}, 'blocks_3': {'compression': 0.125, 'head': 47.065564700002746, 'tail': 26.13525644666879}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 59.890829713331186, 'tail': 23.04009174666741}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 74.50304056666633, 'tail': 21.999628683330837}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 81.68961331999829, 'tail': 19.82456083666572}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 88.93408309999964, 'tail': 17.652905503333994}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 97.23672791333229, 'tail': 15.820995390001068}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 106.98852574666792, 'tail': 14.129450156666886}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 120.5877949733349, 'tail': 11.890332890000838}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 136.47477047333572, 'tail': 11.3458622933346}, 'blocks_12': {'compression': 0.015625, 'head': 148.02516341666887, 'tail': 8.170621666668012}, 'blocks_13': {'compression': 0.015625, 'head': 157.26432909666678, 'tail': 6.274418350000512}, 'blocks_14': {'compression': 0.015625, 'head': 167.69726473666802, 'tail': 4.533012006665254}, 'blocks_15': {'compression': 0.015625, 'head': 177.84980260000034, 'tail': 2.9061119800007873}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 189.4756554833354, 'tail': 0.8423709033316603}}, '14': {'whole_device': 209.3230695166676, 'whole_edge': 36.14700761999908, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.1000663533353263, 'tail': 36.628554249997855}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 12.550493096669015, 'tail': 34.213437746666386}, 'blocks_2': {'compression': 0.125, 'head': 33.19420116999936, 'tail': 28.93028010333486}, 'blocks_3': {'compression': 0.125, 'head': 49.95984276666907, 'tail': 26.948323110000274}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 63.39197995666533, 'tail': 24.606177100001027}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 77.74918222333326, 'tail': 22.793120880002483}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 85.3533980633377, 'tail': 20.40847658333708}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 92.96343544666645, 'tail': 17.92945336000533}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 101.07828604000436, 'tail': 16.311412309999774}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 112.02220974333613, 'tail': 14.095140126664774}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 125.8308652766694, 'tail': 15.035702686667111}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 141.85292307333535, 'tail': 10.90898856666172}, 'blocks_12': {'compression': 0.015625, 'head': 154.50900279333536, 'tail': 8.503456283330404}, 'blocks_13': {'compression': 0.015625, 'head': 166.86271057666696, 'tail': 6.283408816664935}, 'blocks_14': {'compression': 0.015625, 'head': 180.52626456666985, 'tail': 4.447062026671725}, 'blocks_15': {'compression': 0.015625, 'head': 192.82513625332894, 'tail': 2.8978969266669687}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 207.330259253334, 'tail': 0.9480420799991407}}, '15': {'whole_device': 211.6716910666643, 'whole_edge': 37.0079497133338, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.1505555900027202, 'tail': 35.756809523336415}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 13.371906149999024, 'tail': 33.44407349333172}, 'blocks_2': {'compression': 0.125, 'head': 34.99254469000031, 'tail': 29.50138722999933}, 'blocks_3': {'compression': 0.125, 'head': 52.74979894333228, 'tail': 27.379626753336197}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 66.30236828999841, 'tail': 24.657985973329534}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 83.68405432999982, 'tail': 23.05692915667047}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 92.76023643000372, 'tail': 20.532766596667596}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 100.66271740333225, 'tail': 18.257884269999828}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 109.6789246833335, 'tail': 16.380451240002003}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 120.15171359999536, 'tail': 17.30002743000417}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 135.09399997999935, 'tail': 12.491803666665268}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 153.59162092666642, 'tail': 10.506760503333984}, 'blocks_12': {'compression': 0.015625, 'head': 164.29782074666946, 'tail': 8.464198423334892}, 'blocks_13': {'compression': 0.015625, 'head': 174.54258219999852, 'tail': 6.338662433330076}, 'blocks_14': {'compression': 0.015625, 'head': 185.4879294300008, 'tail': 4.763023046671151}, 'blocks_15': {'compression': 0.015625, 'head': 197.37589319666466, 'tail': 3.291743756666013}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 207.98999784333623, 'tail': 0.988456240005083}}, '16': {'whole_device': 214.2539528000028, 'whole_edge': 35.208178233333456, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.2658320633308904, 'tail': 35.64499027999773}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 14.135740586668058, 'tail': 33.00174847666616}, 'blocks_2': {'compression': 0.125, 'head': 36.6017399033323, 'tail': 30.174994126664387}, 'blocks_3': {'compression': 0.125, 'head': 54.58980339000239, 'tail': 27.22463505666383}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 69.79291998333186, 'tail': 24.39237154999622}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 85.0642585766703, 'tail': 22.38683266332979}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 92.46978022666856, 'tail': 20.378478050000314}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 101.56790984666563, 'tail': 18.58936058666586}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 108.83054414999908, 'tail': 19.171056393333856}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 119.33472777000134, 'tail': 14.731689150000117}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 136.70545334000053, 'tail': 12.714583276665508}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 150.20865733666747, 'tail': 11.006440113336186}, 'blocks_12': {'compression': 0.015625, 'head': 159.2685261766625, 'tail': 8.83631564666454}, 'blocks_13': {'compression': 0.015625, 'head': 171.6849458733365, 'tail': 6.540137460002977}, 'blocks_14': {'compression': 0.015625, 'head': 184.02391882666657, 'tail': 4.726108353333984}, 'blocks_15': {'compression': 0.015625, 'head': 196.38186498666983, 'tail': 3.550076796667175}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 209.63506930333702, 'tail': 1.2007576099980117}}, '17': {'whole_device': 241.53855959333063, 'whole_edge': 36.13663537666677, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.4703567899996415, 'tail': 35.37941701333693}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 14.64813758332942, 'tail': 33.32042575666492}, 'blocks_2': {'compression': 0.125, 'head': 38.75966377000319, 'tail': 31.19113608333161}, 'blocks_3': {'compression': 0.125, 'head': 60.3215801333378, 'tail': 27.389987376664067}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 78.68473022999751, 'tail': 24.6389894399969}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 96.82433922666557, 'tail': 22.54175332000159}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 105.94185792333519, 'tail': 23.563939696662903}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 115.25372812332837, 'tail': 18.927410906665802}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 126.30778589333202, 'tail': 17.297319603330834}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 138.46594909000487, 'tail': 14.722675343333929}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 153.6411247666668, 'tail': 13.031744719998338}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 170.92273518333363, 'tail': 10.94463718333524}, 'blocks_12': {'compression': 0.015625, 'head': 182.2773474266675, 'tail': 8.354128513334823}, 'blocks_13': {'compression': 0.015625, 'head': 197.20018313999995, 'tail': 7.632937900004133}, 'blocks_14': {'compression': 0.015625, 'head': 210.50837689666272, 'tail': 5.631863100000676}, 'blocks_15': {'compression': 0.015625, 'head': 226.7100110233332, 'tail': 2.91264650333081}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 238.25432914999814, 'tail': 1.2161800666702522}}, '18': {'whole_device': 256.0673971266685, 'whole_edge': 36.3001606366682, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.610383133336048, 'tail': 35.22192675000042}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 15.264437476665384, 'tail': 33.99179917666818}, 'blocks_2': {'compression': 0.125, 'head': 40.57279900999977, 'tail': 34.38532127333019}, 'blocks_3': {'compression': 0.125, 'head': 63.11959556999985, 'tail': 29.636241073330893}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 81.89527776333004, 'tail': 28.622070999996748}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 101.65223600333775, 'tail': 23.337354769998154}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 111.8510145400008, 'tail': 21.99173184666506}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 120.01483952333729, 'tail': 18.77712496333212}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 130.2867774533358, 'tail': 17.21784460999819}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 141.69394117333164, 'tail': 14.624971606669229}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 160.50241047333353, 'tail': 12.710153163334326}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 176.26820984333486, 'tail': 10.755073860000266}, 'blocks_12': {'compression': 0.015625, 'head': 190.60652895666863, 'tail': 8.444767133332789}, 'blocks_13': {'compression': 0.015625, 'head': 206.73608077000003, 'tail': 6.908438093329702}, 'blocks_14': {'compression': 0.015625, 'head': 223.35117639999834, 'tail': 4.698523560000467}, 'blocks_15': {'compression': 0.015625, 'head': 237.83475960666692, 'tail': 3.0997735599945977}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 252.8114632300033, 'tail': 0.8447628133338488}}, '19': {'whole_device': 257.2475088033328, 'whole_edge': 38.71124358000088, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.684354749999329, 'tail': 38.67232681000436}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 16.179263699996227, 'tail': 36.36736189667014}, 'blocks_2': {'compression': 0.125, 'head': 42.20703627333326, 'tail': 31.872756390002905}, 'blocks_3': {'compression': 0.125, 'head': 66.64463933666411, 'tail': 27.26098600000114}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 85.46336901333537, 'tail': 25.788917190002394}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 104.83563902333722, 'tail': 22.542881746661198}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 115.48880124000182, 'tail': 21.00192169999597}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 124.52581238666728, 'tail': 23.018810830005048}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 133.53929005666942, 'tail': 18.87978219666669}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 148.8655538799988, 'tail': 15.465535830001802}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 166.3169380666659, 'tail': 13.153926806668702}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 184.48773675333237, 'tail': 10.544058799999524}, 'blocks_12': {'compression': 0.015625, 'head': 195.82858926666327, 'tail': 8.382992713335017}, 'blocks_13': {'compression': 0.015625, 'head': 211.34897210666773, 'tail': 8.353837893337186}, 'blocks_14': {'compression': 0.015625, 'head': 224.89616075666467, 'tail': 5.158021759998519}, 'blocks_15': {'compression': 0.015625, 'head': 241.9022746466665, 'tail': 3.210731536667784}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 253.6885874199955, 'tail': 1.2243558066681242}}, '20': {'whole_device': 262.2024740500031, 'whole_edge': 37.307354760002156, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.8744636833289405, 'tail': 35.7476448899979}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 16.774646573333786, 'tail': 34.43437050000284}, 'blocks_2': {'compression': 0.125, 'head': 44.446294309994606, 'tail': 36.54749653000181}, 'blocks_3': {'compression': 0.125, 'head': 68.08543163000043, 'tail': 27.907902566663928}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 89.44476957333487, 'tail': 28.02802500333807}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 109.13155040666727, 'tail': 23.718057630000356}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 119.1292812866656, 'tail': 22.472759600004792}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 130.1710700033315, 'tail': 18.614831946670165}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 138.94188401000065, 'tail': 17.73447422000269}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 153.01642273666704, 'tail': 15.355860020002487}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 171.98695011333257, 'tail': 15.711053123328988}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 191.33673618333583, 'tail': 11.77764642333083}, 'blocks_12': {'compression': 0.015625, 'head': 206.37396423333485, 'tail': 8.761544086664799}, 'blocks_13': {'compression': 0.015625, 'head': 219.31691980333804, 'tail': 6.5004769233322195}, 'blocks_14': {'compression': 0.015625, 'head': 231.85379833666957, 'tail': 4.352245116666988}, 'blocks_15': {'compression': 0.015625, 'head': 247.34633177333308, 'tail': 3.557658680001623}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 259.2958642300012, 'tail': 1.0148947366663683}}, '21': {'whole_device': 284.6763049800029, 'whole_edge': 37.4038137300037, 'blocks_0': {'compression': 0.6666666666666666, 'head': 2.9003376066672595, 'tail': 37.76176216333018}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 18.302078466664774, 'tail': 34.80951962333469}, 'blocks_2': {'compression': 0.125, 'head': 48.45717414333194, 'tail': 31.525034626665725}, 'blocks_3': {'compression': 0.125, 'head': 74.71842917666436, 'tail': 27.62608165666582}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 96.52350622333566, 'tail': 25.16207183332881}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 117.78453151666933, 'tail': 27.870391569995263}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 127.7325002033346, 'tail': 20.688900553335166}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 139.50849086999975, 'tail': 19.079472783329646}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 150.3196618966649, 'tail': 18.23929861333454}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 164.0473061633323, 'tail': 14.84837530333607}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 183.63375935666528, 'tail': 13.259529429997201}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 205.00583936333595, 'tail': 10.856758506670303}, 'blocks_12': {'compression': 0.015625, 'head': 217.87421162666456, 'tail': 8.528964793331397}, 'blocks_13': {'compression': 0.015625, 'head': 237.0903710233324, 'tail': 6.561876710002252}, 'blocks_14': {'compression': 0.015625, 'head': 250.74799621666293, 'tail': 4.848406446665952}, 'blocks_15': {'compression': 0.015625, 'head': 264.85423231333095, 'tail': 2.977307250002923}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 278.7452745633285, 'tail': 1.2316994166697743}}, '22': {'whole_device': 304.25194748000047, 'whole_edge': 38.82850228999814, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.19248899999972, 'tail': 38.5555093133371}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 19.39158586999838, 'tail': 36.36082481333384}, 'blocks_2': {'compression': 0.125, 'head': 50.36914852333818, 'tail': 31.997740540003484}, 'blocks_3': {'compression': 0.125, 'head': 77.49566197999836, 'tail': 28.707892556667503}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 94.5241726300022, 'tail': 25.65556426333084}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 115.53994268666429, 'tail': 23.425789509995713}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 126.68203110333101, 'tail': 21.353848890000034}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 136.11930246333336, 'tail': 19.16653839999829}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 148.07950173333666, 'tail': 18.67467638333134}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 164.01136485999814, 'tail': 15.76785419333343}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 182.70828848666497, 'tail': 13.184964366664644}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 202.52041844666869, 'tail': 10.834333140004068}, 'blocks_12': {'compression': 0.015625, 'head': 217.65121772000083, 'tail': 8.63501607666573}, 'blocks_13': {'compression': 0.015625, 'head': 233.9233177099959, 'tail': 6.374582203334285}, 'blocks_14': {'compression': 0.015625, 'head': 256.3001272099973, 'tail': 4.560264569997041}, 'blocks_15': {'compression': 0.015625, 'head': 271.84255136666854, 'tail': 2.4911337600012}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 286.9221887933357, 'tail': 0.9081951866634578}}, '23': {'whole_device': 286.62013813333635, 'whole_edge': 38.87088991333561, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.27230681332973, 'tail': 41.22009649000271}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 18.87220575333534, 'tail': 38.718141816668016}, 'blocks_2': {'compression': 0.125, 'head': 50.42189555333001, 'tail': 31.948716599999898}, 'blocks_3': {'compression': 0.125, 'head': 76.68304819667051, 'tail': 29.4506907599983}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 97.77219192666962, 'tail': 26.013495186665143}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 120.51120687333119, 'tail': 23.641303283329762}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 129.71750889999993, 'tail': 21.271003270000318}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 141.06894986333523, 'tail': 19.49284568000318}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 151.07897851666468, 'tail': 21.947316006668796}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 167.29023122000095, 'tail': 17.499242089998006}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 190.1300687200031, 'tail': 13.094664970000546}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 209.67206354334243, 'tail': 11.089434839996102}, 'blocks_12': {'compression': 0.015625, 'head': 223.0960448066738, 'tail': 8.807726750007228}, 'blocks_13': {'compression': 0.015625, 'head': 239.35528930333626, 'tail': 7.853165369997441}, 'blocks_14': {'compression': 0.015625, 'head': 255.05856511666934, 'tail': 4.8778080033298465}, 'blocks_15': {'compression': 0.015625, 'head': 272.63431339667784, 'tail': 2.861287946664864}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 284.0801111499968, 'tail': 1.0184363833347259}}, '24': {'whole_device': 289.45027673333243, 'whole_edge': 41.011446506660526, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.164662873326354, 'tail': 45.39501890333971}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 19.307731786660344, 'tail': 39.309357316669775}, 'blocks_2': {'compression': 0.125, 'head': 51.870663256668195, 'tail': 33.88202405666865}, 'blocks_3': {'compression': 0.125, 'head': 79.5121761866661, 'tail': 29.64547601666709}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 101.93437895000291, 'tail': 26.931480536659365}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 124.05793429999903, 'tail': 24.49467855999198}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 134.68753081999847, 'tail': 22.195295429992257}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 144.12411178999415, 'tail': 20.350768479996383}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 155.97959516000023, 'tail': 18.196341950000107}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 169.5506306533328, 'tail': 16.026751490001818}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 192.87818792666562, 'tail': 13.842506910004886}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 214.13011971333617, 'tail': 11.572806859997703}, 'blocks_12': {'compression': 0.015625, 'head': 226.73413002000112, 'tail': 8.685408230000272}, 'blocks_13': {'compression': 0.015625, 'head': 241.08638385332597, 'tail': 6.907927676669108}, 'blocks_14': {'compression': 0.015625, 'head': 256.0140607333354, 'tail': 4.641859926668985}, 'blocks_15': {'compression': 0.015625, 'head': 275.4251720866645, 'tail': 3.24350608666767}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 288.1671666366674, 'tail': 1.0814694133296143}}, '25': {'whole_device': 299.27282258333435, 'whole_edge': 40.11682448000405, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.1244885733394767, 'tail': 38.62249340666798}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 20.14820082667332, 'tail': 36.51832885333231}, 'blocks_2': {'compression': 0.125, 'head': 54.43857273333075, 'tail': 39.85496462000204}, 'blocks_3': {'compression': 0.125, 'head': 81.08896243667307, 'tail': 29.612737369995255}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 105.48616560332448, 'tail': 26.49984455332742}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 128.57091110333081, 'tail': 26.554024196666433}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 138.80368233333382, 'tail': 21.924548043340714}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 149.91421117333326, 'tail': 20.7171343533264}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 160.29740695000024, 'tail': 17.420664789994287}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 177.00181678000564, 'tail': 19.507088669997756}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 197.4133530933371, 'tail': 14.74560901666943}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 220.4817321100078, 'tail': 12.107770293332578}, 'blocks_12': {'compression': 0.015625, 'head': 233.63905196999744, 'tail': 9.063947370001793}, 'blocks_13': {'compression': 0.015625, 'head': 249.11733527666607, 'tail': 6.88442350000211}, 'blocks_14': {'compression': 0.015625, 'head': 266.306873663331, 'tail': 4.613388849999562}, 'blocks_15': {'compression': 0.015625, 'head': 281.7557782533307, 'tail': 3.4670719466642668}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 296.2828631166606, 'tail': 1.23071185000299}}, '26': {'whole_device': 321.938623023331, 'whole_edge': 39.750642423338526, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.214442673330874, 'tail': 39.04754170334248}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 20.87128851667027, 'tail': 37.4247059533324}, 'blocks_2': {'compression': 0.125, 'head': 56.30035125333961, 'tail': 39.353578713332055}, 'blocks_3': {'compression': 0.125, 'head': 83.56836507001087, 'tail': 31.351925380004108}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 108.50742419666251, 'tail': 26.87791916666659}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 132.42550584665878, 'tail': 26.56534421000591}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 142.72296990999166, 'tail': 21.71190329332603}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 153.7232069899983, 'tail': 20.736020966663393}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 164.6377402700091, 'tail': 17.847364326674626}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 181.22114956666337, 'tail': 18.942857603336353}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 202.4013386433338, 'tail': 14.461236296665447}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 225.86865766000605, 'tail': 13.401804510006816}, 'blocks_12': {'compression': 0.015625, 'head': 239.56639376333138, 'tail': 9.799085710001236}, 'blocks_13': {'compression': 0.015625, 'head': 259.8117621566659, 'tail': 6.694819199995739}, 'blocks_14': {'compression': 0.015625, 'head': 278.71814151333336, 'tail': 4.916853400003068}, 'blocks_15': {'compression': 0.015625, 'head': 301.44940302332543, 'tail': 3.1989892266695583}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 318.2131682066635, 'tail': 1.4015486066637095}}, '27': {'whole_device': 314.93340563333425, 'whole_edge': 40.868537226670014, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.3299978266707817, 'tail': 47.707719870001405}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 21.55071212667584, 'tail': 40.835248663327846}, 'blocks_2': {'compression': 0.125, 'head': 57.379709240000615, 'tail': 34.87423349333161}, 'blocks_3': {'compression': 0.125, 'head': 87.55107812333638, 'tail': 30.442658236667437}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 111.33715501667514, 'tail': 28.637580199999018}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 135.04379195666843, 'tail': 24.275815223336394}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 146.86990119000257, 'tail': 22.729571233333747}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 157.61641543333099, 'tail': 20.122967039994062}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 170.3207246133267, 'tail': 19.016933036667375}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 185.2881043033267, 'tail': 17.78258899333499}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 209.27492538332444, 'tail': 14.34426275999916}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 230.9181658933327, 'tail': 11.033241629993427}, 'blocks_12': {'compression': 0.015625, 'head': 244.7237608500048, 'tail': 8.810722476664523}, 'blocks_13': {'compression': 0.015625, 'head': 262.673202436672, 'tail': 8.290817659993383}, 'blocks_14': {'compression': 0.015625, 'head': 279.52312135000585, 'tail': 4.819329433327463}, 'blocks_15': {'compression': 0.015625, 'head': 297.17490745999385, 'tail': 2.819331346666634}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 310.06612351667474, 'tail': 1.196644183328317}}, '28': {'whole_device': 322.5445467766622, 'whole_edge': 41.42647316000269, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.477193970005222, 'tail': 42.439359149999895}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 22.42440231000122, 'tail': 42.672895946670906}, 'blocks_2': {'compression': 0.125, 'head': 59.84536452334093, 'tail': 34.184429763323955}, 'blocks_3': {'compression': 0.125, 'head': 89.92586999000196, 'tail': 31.76538546666658}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 113.66134713333547, 'tail': 27.420362993337523}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 138.62472734666272, 'tail': 25.44414926332441}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 149.32640228666665, 'tail': 23.05854258999413}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 161.81204918333, 'tail': 20.854955626673473}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 172.51146162333802, 'tail': 18.931720323331927}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 191.8428805733371, 'tail': 16.924403766667336}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 212.96786783999173, 'tail': 14.204361183328729}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 234.34988463666133, 'tail': 11.78298859000885}, 'blocks_12': {'compression': 0.015625, 'head': 250.07273065665993, 'tail': 8.778783853328303}, 'blocks_13': {'compression': 0.015625, 'head': 266.93702693667245, 'tail': 7.7403684366678736}, 'blocks_14': {'compression': 0.015625, 'head': 286.70809251999646, 'tail': 5.019081093329684}, 'blocks_15': {'compression': 0.015625, 'head': 301.54965098000196, 'tail': 3.1205056866747327}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 316.2152384366709, 'tail': 1.0996920966620867}}, '29': {'whole_device': 326.8467209733353, 'whole_edge': 42.801557563337454, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.787985180000154, 'tail': 43.08145838999432}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 23.172607473340275, 'tail': 39.67563756666399}, 'blocks_2': {'compression': 0.125, 'head': 61.324682113336166, 'tail': 35.44099616666548}, 'blocks_3': {'compression': 0.125, 'head': 92.10274912666742, 'tail': 30.918671403330034}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 116.65374994999486, 'tail': 28.279260183323156}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 142.06055574666001, 'tail': 25.271909166670714}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 153.54865692999738, 'tail': 25.640824176662136}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 165.25689329332332, 'tail': 21.71987563999816}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 179.0411253866599, 'tail': 18.98753145333709}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 194.48559122333486, 'tail': 16.508078336664767}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 216.5933214733377, 'tail': 13.826788269992297}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 239.7629171666631, 'tail': 12.170776493342904}, 'blocks_12': {'compression': 0.015625, 'head': 254.66276330333736, 'tail': 9.692153246663414}, 'blocks_13': {'compression': 0.015625, 'head': 274.7473834866711, 'tail': 6.990036400008345}, 'blocks_14': {'compression': 0.015625, 'head': 289.92115216666815, 'tail': 4.876929413330799}, 'blocks_15': {'compression': 0.015625, 'head': 306.51235006000206, 'tail': 3.1000521166667263}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 321.9082325866717, 'tail': 1.0639373500089278}}, '30': {'whole_device': 355.80934558332956, 'whole_edge': 42.93209596999077, 'blocks_0': {'compression': 0.6666666666666666, 'head': 3.7033188366573695, 'tail': 42.374916823331056}, 'blocks_1': {'compression': 0.3333333333333333, 'head': 23.552220340000837, 'tail': 39.51263254999503}, 'blocks_2': {'compression': 0.125, 'head': 63.372407113335306, 'tail': 35.41510172999551}, 'blocks_3': {'compression': 0.125, 'head': 94.23937085333213, 'tail': 30.752084773339448}, 'blocks_4': {'compression': 0.052083333333333336, 'head': 119.83289556334057, 'tail': 32.25721836000351}, 'blocks_5': {'compression': 0.052083333333333336, 'head': 145.70108623667085, 'tail': 25.946956706660178}, 'blocks_6': {'compression': 0.026041666666666668, 'head': 159.00796590000635, 'tail': 24.473452746666833}, 'blocks_7': {'compression': 0.026041666666666668, 'head': 170.22262416000257, 'tail': 21.871408520006906}, 'blocks_8': {'compression': 0.026041666666666668, 'head': 181.9086646866587, 'tail': 19.23765858333354}, 'blocks_9': {'compression': 0.036458333333333336, 'head': 198.0333674900006, 'tail': 17.000458906671458}, 'blocks_10': {'compression': 0.036458333333333336, 'head': 221.67408215666606, 'tail': 16.841849090002746}, 'blocks_11': {'compression': 0.036458333333333336, 'head': 246.52724330000638, 'tail': 11.939994376674198}, 'blocks_12': {'compression': 0.015625, 'head': 261.6695405733359, 'tail': 9.177442273333629}, 'blocks_13': {'compression': 0.015625, 'head': 282.96643390667066, 'tail': 7.088485496666787}, 'blocks_14': {'compression': 0.015625, 'head': 306.08730211332534, 'tail': 5.7252231133315945}, 'blocks_15': {'compression': 0.015625, 'head': 330.70851463333383, 'tail': 3.2043491666627233}, 'blocks_16': {'compression': 0.026041666666666668, 'head': 350.1745630066701, 'tail': 1.1117130433315956}}}\n",
      "['blocks_3', 'blocks_6', 'blocks_9', 'blocks_17', 'blocks_19', 'blocks_23']\n",
      "[{'layer_name': 'blocks_3', 'compression': 0.5, 'cnn_layer_number': 13, 'block_number': 3}, {'layer_name': 'blocks_6', 'compression': 0.19253333333333333, 'cnn_layer_number': 28, 'block_number': 6}, {'layer_name': 'blocks_9', 'compression': 0.06417777777777778, 'cnn_layer_number': 43, 'block_number': 9}, {'layer_name': 'blocks_17', 'compression': 0.04545925925925926, 'cnn_layer_number': 83, 'block_number': 17}, {'layer_name': 'blocks_19', 'compression': 0.04296296296296296, 'cnn_layer_number': 93, 'block_number': 19}, {'layer_name': 'blocks_23', 'compression': 0.02148148148148148, 'cnn_layer_number': 113, 'block_number': 23}]\n",
      "{'1': {'whole_device': 115.05890115666641, 'whole_edge': 33.403415089999655, 'blocks_3': {'compression': 0.5, 'head': 16.692602493333577, 'tail': 29.61196232666642}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 29.815285576666685, 'tail': 20.545710316666828}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 44.53172772333346, 'tail': 14.058842543333487}}, '2': {'whole_device': 126.1887470166668, 'whole_edge': 30.267452260000027, 'blocks_3': {'compression': 0.5, 'head': 26.089713006666294, 'tail': 25.347577789999985}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 41.84573273333323, 'tail': 19.767864676666704}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 56.10159230999973, 'tail': 13.006460536666964}}, '3': {'whole_device': 144.19287482333326, 'whole_edge': 30.990268639999762, 'blocks_3': {'compression': 0.5, 'head': 17.37994143333405, 'tail': 24.788130066666174}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 54.79666091666635, 'tail': 23.54306559666611}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 74.27969074999965, 'tail': 14.97392907333354}}, '4': {'whole_device': 160.79486920666645, 'whole_edge': 30.38587956333307, 'blocks_3': {'compression': 0.5, 'head': 21.488422809999673, 'tail': 27.10003754333381}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 42.550190850000334, 'tail': 19.761141059999925}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 88.40812390666694, 'tail': 13.195841503332606}}, '5': {'whole_device': 185.56853930000065, 'whole_edge': 30.86761063666624, 'blocks_3': {'compression': 0.5, 'head': 23.31265043000106, 'tail': 24.617780229999276}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 45.834277176666845, 'tail': 19.12662526333255}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 102.72277673000038, 'tail': 15.255971513332346}}, '6': {'whole_device': 206.8975400666659, 'whole_edge': 32.787212816667, 'blocks_3': {'compression': 0.5, 'head': 26.03998596999948, 'tail': 25.766537119999764}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 51.59275627666678, 'tail': 20.050617023333267}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 68.9439434533339, 'tail': 14.529761026666772}}, '7': {'whole_device': 142.56694529000015, 'whole_edge': 31.237924743333373, 'blocks_3': {'compression': 0.5, 'head': 28.725070246667503, 'tail': 31.263022243333577}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 63.39501594000012, 'tail': 20.33243663333451}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 75.76193830000041, 'tail': 14.373448883332761}}, '8': {'whole_device': 154.73512497666889, 'whole_edge': 32.11837467666859, 'blocks_3': {'compression': 0.5, 'head': 32.109663530000034, 'tail': 26.844940249999734}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 61.52975756333338, 'tail': 19.87714959666543}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 81.97500029000062, 'tail': 16.71841120333132}}, '9': {'whole_device': 168.16287912666667, 'whole_edge': 39.46960971666765, 'blocks_3': {'compression': 0.5, 'head': 35.776396653333606, 'tail': 30.08933815666751}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 69.01208128666742, 'tail': 22.54970005333538}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 89.37207511333327, 'tail': 15.179496033333635}}, '10': {'whole_device': 173.49722306999865, 'whole_edge': 31.886482493334068, 'blocks_3': {'compression': 0.5, 'head': 38.942629503332384, 'tail': 24.924379646666544}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 72.90494576000128, 'tail': 18.94228452999717}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 97.00966690000011, 'tail': 15.11103376333267}}, '11': {'whole_device': 191.8725585566669, 'whole_edge': 34.65506510666577, 'blocks_3': {'compression': 0.5, 'head': 40.974804863332494, 'tail': 25.35413859000073}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 78.98122746666863, 'tail': 18.658868233333123}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 101.29556588666674, 'tail': 13.728877916664715}}, '12': {'whole_device': 197.05411766333478, 'whole_edge': 33.030973503333975, 'blocks_3': {'compression': 0.5, 'head': 43.62175916333399, 'tail': 24.83003624999886}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 84.08002620333112, 'tail': 19.4994881900008}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 108.57303496999823, 'tail': 18.08128346666611}}, '13': {'whole_device': 192.95985891666837, 'whole_edge': 33.127780773335566, 'blocks_3': {'compression': 0.5, 'head': 47.065564700002746, 'tail': 26.13525644666879}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 81.68961331999829, 'tail': 19.82456083666572}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 106.98852574666792, 'tail': 14.129450156666886}}, '14': {'whole_device': 209.3230695166676, 'whole_edge': 36.14700761999908, 'blocks_3': {'compression': 0.5, 'head': 49.95984276666907, 'tail': 26.948323110000274}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 85.3533980633377, 'tail': 20.40847658333708}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 112.02220974333613, 'tail': 14.095140126664774}}, '15': {'whole_device': 211.6716910666643, 'whole_edge': 37.0079497133338, 'blocks_3': {'compression': 0.5, 'head': 52.74979894333228, 'tail': 27.379626753336197}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 92.76023643000372, 'tail': 20.532766596667596}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 120.15171359999536, 'tail': 17.30002743000417}}, '16': {'whole_device': 214.2539528000028, 'whole_edge': 35.208178233333456, 'blocks_3': {'compression': 0.5, 'head': 54.58980339000239, 'tail': 27.22463505666383}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 92.46978022666856, 'tail': 20.378478050000314}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 119.33472777000134, 'tail': 14.731689150000117}}, '17': {'whole_device': 241.53855959333063, 'whole_edge': 36.13663537666677, 'blocks_3': {'compression': 0.5, 'head': 60.3215801333378, 'tail': 27.389987376664067}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 105.94185792333519, 'tail': 23.563939696662903}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 138.46594909000487, 'tail': 14.722675343333929}}, '18': {'whole_device': 256.0673971266685, 'whole_edge': 36.3001606366682, 'blocks_3': {'compression': 0.5, 'head': 63.11959556999985, 'tail': 29.636241073330893}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 111.8510145400008, 'tail': 21.99173184666506}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 141.69394117333164, 'tail': 14.624971606669229}}, '19': {'whole_device': 257.2475088033328, 'whole_edge': 38.71124358000088, 'blocks_3': {'compression': 0.5, 'head': 66.64463933666411, 'tail': 27.26098600000114}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 115.48880124000182, 'tail': 21.00192169999597}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 148.8655538799988, 'tail': 15.465535830001802}}, '20': {'whole_device': 262.2024740500031, 'whole_edge': 37.307354760002156, 'blocks_3': {'compression': 0.5, 'head': 68.08543163000043, 'tail': 27.907902566663928}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 119.1292812866656, 'tail': 22.472759600004792}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 153.01642273666704, 'tail': 15.355860020002487}}, '21': {'whole_device': 284.6763049800029, 'whole_edge': 37.4038137300037, 'blocks_3': {'compression': 0.5, 'head': 74.71842917666436, 'tail': 27.62608165666582}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 127.7325002033346, 'tail': 20.688900553335166}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 164.0473061633323, 'tail': 14.84837530333607}}, '22': {'whole_device': 304.25194748000047, 'whole_edge': 38.82850228999814, 'blocks_3': {'compression': 0.5, 'head': 77.49566197999836, 'tail': 28.707892556667503}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 126.68203110333101, 'tail': 21.353848890000034}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 164.01136485999814, 'tail': 15.76785419333343}}, '23': {'whole_device': 286.62013813333635, 'whole_edge': 38.87088991333561, 'blocks_3': {'compression': 0.5, 'head': 76.68304819667051, 'tail': 29.4506907599983}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 129.71750889999993, 'tail': 21.271003270000318}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 167.29023122000095, 'tail': 17.499242089998006}}, '24': {'whole_device': 289.45027673333243, 'whole_edge': 41.011446506660526, 'blocks_3': {'compression': 0.5, 'head': 79.5121761866661, 'tail': 29.64547601666709}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 134.68753081999847, 'tail': 22.195295429992257}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 169.5506306533328, 'tail': 16.026751490001818}}, '25': {'whole_device': 299.27282258333435, 'whole_edge': 40.11682448000405, 'blocks_3': {'compression': 0.5, 'head': 81.08896243667307, 'tail': 29.612737369995255}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 138.80368233333382, 'tail': 21.924548043340714}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 177.00181678000564, 'tail': 19.507088669997756}}, '26': {'whole_device': 321.938623023331, 'whole_edge': 39.750642423338526, 'blocks_3': {'compression': 0.5, 'head': 83.56836507001087, 'tail': 31.351925380004108}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 142.72296990999166, 'tail': 21.71190329332603}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 181.22114956666337, 'tail': 18.942857603336353}}, '27': {'whole_device': 314.93340563333425, 'whole_edge': 40.868537226670014, 'blocks_3': {'compression': 0.5, 'head': 87.55107812333638, 'tail': 30.442658236667437}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 146.86990119000257, 'tail': 22.729571233333747}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 185.2881043033267, 'tail': 17.78258899333499}}, '28': {'whole_device': 322.5445467766622, 'whole_edge': 41.42647316000269, 'blocks_3': {'compression': 0.5, 'head': 89.92586999000196, 'tail': 31.76538546666658}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 149.32640228666665, 'tail': 23.05854258999413}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 191.8428805733371, 'tail': 16.924403766667336}}, '29': {'whole_device': 326.8467209733353, 'whole_edge': 42.801557563337454, 'blocks_3': {'compression': 0.5, 'head': 92.10274912666742, 'tail': 30.918671403330034}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 153.54865692999738, 'tail': 25.640824176662136}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 194.48559122333486, 'tail': 16.508078336664767}}, '30': {'whole_device': 355.80934558332956, 'whole_edge': 42.93209596999077, 'blocks_3': {'compression': 0.5, 'head': 94.23937085333213, 'tail': 30.752084773339448}, 'blocks_6': {'compression': 0.19253333333333333, 'head': 159.00796590000635, 'tail': 24.473452746666833}, 'blocks_9': {'compression': 0.06417777777777778, 'head': 198.0333674900006, 'tail': 17.000458906671458}}}\n"
     ]
    }
   ],
   "source": [
    "def load_batch_table1():\n",
    "    batch_table_path = 'batch_table/efficient_baseline_v5.json'    # b0\n",
    "    # batch_table_path = 'batch_table/efficientb3_baseline_v10.json'   #b3\n",
    "    with open(batch_table_path, 'r') as batch_table_file:\n",
    "        return json.loads(batch_table_file.read())\n",
    "\n",
    "batch_table1 = load_batch_table1()\n",
    "print(batch_table1)\n",
    "\n",
    "layer_names = []\n",
    "for i, natural_bottleneck in enumerate(natural_bottlenecks):\n",
    "    # pretty_layer_name = '%s_%02d' % (\n",
    "    # natural_bottleneck['layer_name'].split('_')[0],\n",
    "    # int(natural_bottleneck['layer_name'].split('_')[-1])\n",
    "    # )\n",
    "    # print(pretty_layer_name)\n",
    "    layer_names.append(natural_bottleneck['layer_name'])\n",
    "print(layer_names)\n",
    "for i in range(len(natural_bottlenecks)):\n",
    "    natural_bottlenecks[i][\"layer_name\"] = layer_names[i]\n",
    "    # natural_bottlenecks[i][\"compression\"] = i\n",
    "    \n",
    "print(natural_bottlenecks)\n",
    "\n",
    "\n",
    "def get_items_for_values(dictionary, whole_device, whole_edge, target_key):\n",
    "    key_len = len(dictionary)\n",
    "    new_dict = {}\n",
    "    for i in range(1, key_len+1):\n",
    "        new_dict[str(i)] = {}\n",
    "        for key, value in dictionary[str(i)].items():\n",
    "            if key in \"whole_device\" and whole_device:\n",
    "                new_dict[str(i)][key] = value\n",
    "            if key in \"whole_edge\" and whole_edge:\n",
    "                new_dict[str(i)][key] = value\n",
    "            if key in target_key:\n",
    "                new_dict[str(i)][key] = value\n",
    "                # new_dict[str(i)][key]['compression'] = 0\n",
    "                for natural in natural_bottlenecks:\n",
    "                    if natural['layer_name'] == key:\n",
    "                        new_dict[str(i)][key]['compression'] = natural['compression']\n",
    "    return new_dict\n",
    "# ベースラインのバッチテーブルからバッチテーブルのキーがwhole_deviceとwhole_edgeであるデータと、natural_bottlenekとなる\n",
    "# ブロックのデータを抜き出し、natural_bottlenekとなるブロックのcompressionの値を get_natural_bottlenecks()で求めた別のモデルのcompressionの値に更新\n",
    "print(get_items_for_values(batch_table1, True, True, layer_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_table = get_items_for_values(batch_table1, True, False, layer_names)\n",
    "# batch_table = get_items_for_values(batch_table1, True, True, layer_names)\n",
    "INFERENCE_PLOT_DIR_MODIFIED = 'inference_plot_modified'\n",
    "save_dir = f'./{INFERENCE_PLOT_DIR_MODIFIED}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "create_inference_time_only(batch_table, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gainのグラフを作成するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max gain: 38.59692667482385\n",
      "average gain: 29.38170668540817\n"
     ]
    }
   ],
   "source": [
    "# quanteffnet_w8a8_v8\n",
    "existing = \"int8_b3_v1.npy\"\n",
    "new = \"quanteffnet_cfg_2468_b3_Ours ($\\lambda = 0.025$).npy\"\n",
    "\n",
    "y = np.load(os.path.join('inference_time', existing), allow_pickle='TRUE')  #従来\n",
    "z = np.load(os.path.join('inference_time', new), allow_pickle='TRUE')  #提案\n",
    "# quanteffnet_cfg_2468_ours4_v9\n",
    "absolute_diff = y - z\n",
    "relative_diff = absolute_diff / y\n",
    "diff_percent = relative_diff * 100\n",
    "heatmap_data = np.clip(\n",
    "    diff_percent,\n",
    "    0,\n",
    "    None\n",
    ")\n",
    "heatmap_data = diff_percent\n",
    "\n",
    "\n",
    "fig, main_ax = plt.subplots()\n",
    "fig.set_size_inches(FIGURE_SIZE[0], FIGURE_SIZE[1])\n",
    "ax = sns.heatmap(np.array(heatmap_data), cbar_kws={'label': 'Gain %'}, ax=main_ax, linewidths=0.3, linecolor='w')\n",
    "ax.set_xlabel('Data Rate (MBps)')\n",
    "ax.set_ylabel('Batch Size')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Adjust y-ticks\n",
    "n = 2  # Display every 2nd tick\n",
    "yticks = ax.yaxis.get_major_ticks()\n",
    "for i, tick in enumerate(yticks):\n",
    "    if i % n == 0:\n",
    "        tick.label1.set_visible(True)\n",
    "    else:\n",
    "        tick.label1.set_visible(False)\n",
    "\n",
    "\n",
    "GAIN_DIR = os.path.join('gain_graph')\n",
    "if not os.path.exists(GAIN_DIR):\n",
    "    os.makedirs(GAIN_DIR)\n",
    "save_path = os.path.join(GAIN_DIR, '%s_gain_over_%s.svg' % (\n",
    "existing,\n",
    "new,))\n",
    "ax.figure.savefig(save_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "max_value = max([max(sublist) for sublist in heatmap_data])\n",
    "print(\"max gain:\",max_value)\n",
    "\n",
    "sublist_sums = [sum(sublist)/len(sublist) for sublist in heatmap_data]\n",
    "average = sum(sublist_sums) / len(heatmap_data)\n",
    "print(\"average gain:\", average)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edmips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
